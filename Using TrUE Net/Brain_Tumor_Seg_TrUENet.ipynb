{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qviQjOd1Yu1U",
        "outputId": "24f6efcb-81c1-4260-a654-1e7fa869a83c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "basepath_images= \"imagesTr/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gE3WoYQHY9np"
      },
      "outputs": [],
      "source": [
        "#import nibabel as nib\n",
        "import csv\n",
        "import imageio\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', '.*do not.*', )\n",
        "import nibabel as nib \n",
        "\n",
        "def preprocess_img(img):\n",
        "  return (img-img.mean())/(img.std()+1e-16)\n",
        "\n",
        "fields = ['Name']\n",
        "\n",
        "\n",
        "new_img_dir = \"/home/cds/Desktop/MIG Course project/Self Segmentation project/Using TrUE Net/Image_Training/\"\n",
        "filename = new_img_dir+\"A_images.csv\"\n",
        "# writing to csv file \n",
        "# with open(filename, 'w') as csvfile:\n",
        "#   writer = csv.writer(csvfile) \n",
        "#   writer.writerow(fields) \n",
        "#   for i in range(0, 15):\n",
        "#     img = nib.load(basepath_images+'BRATS_' + '{0:03}'.format(i+1) + '.nii.gz')\n",
        "#     img_arr  = img.get_fdata()\n",
        "#     #print(img_arr.shape) #(240,240,155,4) i.e channel size at end\n",
        "    \n",
        "#     for j in range(0, img_arr.shape[2]):\n",
        "#       im = img_arr[:,:,j,0]\n",
        "#       im = preprocess_img(im)      \n",
        "#       #print(im)\n",
        "#       img_uint8 = im.astype(np.uint8)      \n",
        "#       file_name = new_img_dir+'image_' + str(i+1) + '_' + str(j+1) + '_.png'\n",
        "#       imageio.imwrite(file_name, im)       \n",
        "#       writer.writerow([file_name]) \n",
        "    \n",
        "    \n",
        "      \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "AUDIco0isK3b",
        "outputId": "3ad38b44-a614-400f-c239-8f01e095ddd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c35ce81f0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.imshow(plt.imread('Image_Training/image_1_62_.png'))\n",
        "#print(np.unique(plt.imread('Images_Tr/image_1_62_.png')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLSkfkCqtwT-",
        "outputId": "10f2ee5c-dbae-4d62-f374-307852a5d4b5"
      },
      "outputs": [],
      "source": [
        "labels_path = \"labelsTr/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sPCgdUCpsJfO"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import csv\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_label(label):\n",
        "  label[label>0] = 1.0\n",
        "  return label\n",
        "\n",
        "\n",
        "fields = ['Name']\n",
        "\n",
        "new_labels_dir = \"/home/cds/Desktop/MIG Course project/Self Segmentation project/Using TrUE Net/Labels_Training/\"\n",
        "filename = new_labels_dir+\"A_labels.csv\"\n",
        "    \n",
        "# writing to csv file \n",
        "# with open(filename, 'w') as csvfile:\n",
        "#   writer = csv.writer(csvfile) \n",
        "#   writer.writerow(fields) \n",
        "#   for i in range(0, 15):\n",
        "#     img = nib.load(labels_path+'BRATS_' + '{0:03}'.format(i+1) + '.nii.gz')\n",
        "#     img_arr  = img.get_fdata()\n",
        "#     #print(img_arr.shape)\n",
        "#     for j in range(0, img_arr.shape[2]):\n",
        "#       im = img_arr[:,:,j]\n",
        "#       im = preprocess_label(im)\n",
        "#       #print(im.shape)\n",
        "#       img_uint8 = im.astype(np.uint8)\n",
        "#       file_name = new_labels_dir+'label_' + str(i+1) + '_' + str(j+1) + '_.png'\n",
        "#       imageio.imwrite(file_name, im)\n",
        "#       writer.writerow([file_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1.]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "test_label = 'Labels_Training/label_2_92_.png'\n",
        "test_img_label = plt.imread(test_label)\n",
        "print(np.unique(test_img_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NOeKAPtlr_ED"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W3PgOYTfAbn0"
      },
      "outputs": [],
      "source": [
        "class BrainTumor(Dataset):\n",
        "    \"\"\"Brain Tumor Segmentation Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file_images, csv_file_labels, root_dir, transform):# transform to tensor\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.names_images = pd.read_csv(csv_file_images)\n",
        "        self.names_labels = pd.read_csv(csv_file_labels)\n",
        "        self.root_dirIimgs = root_dir + 'Image_Training/'\n",
        "        self.root_dirIlabl = root_dir + 'Labels_Training/'\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "\n",
        "        img_name = os.path.join(self.root_dirIimgs,\n",
        "                                self.names_images['Name'][idx])\n",
        "        lab_name = os.path.join(self.root_dirIlabl,\n",
        "                                self.names_labels['Name'][idx])\n",
        "        image = io.imread(img_name)\n",
        "        label = io.imread(lab_name)\n",
        "\n",
        "        #Data augmentation\n",
        "        \n",
        "        if self.transform:  \n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label).long()\n",
        "        # label[label<255]=0\n",
        "        # label = label/255\n",
        "        # label = label.long()\n",
        "        return image,label  # transform the images into tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# class Block(nn.Module):\n",
        "#     def __init__(self,inChannels, outChannels):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(inChannels,outChannels,kernel_size=3)        \n",
        "#         self.conv2 = nn.Conv2d(outChannels,outChannels,kernel_size=3)\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         # Apply conv1=>conv2 => relu        \n",
        "#         tmp = self.conv1(x)\n",
        "#         tmp = self.relu(tmp)\n",
        "#         tmp = self.conv2(tmp)\n",
        "#         tmp = self.relu(tmp)        \n",
        "#         return tmp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self,channels = (1,2,4,8,16)):\n",
        "#         super().__init__()\n",
        "\n",
        "#         #Store encoder and maxpooling\n",
        "#         self.encBlocks = nn.ModuleList(\n",
        "#             [Block(channels[i],channels[i+1])\n",
        "#              for i in range(len(channels)-1)])\n",
        "#         self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         blockOutputs = []\n",
        "\n",
        "#         for i,block in enumerate(self.encBlocks):\n",
        "#             #Pass inputs through the current encoder block, store the outputs and then apply maxpooling            \n",
        "#             x = block(x)\n",
        "#             blockOutputs.append(x)\n",
        "#             x = self.pool(x)\n",
        "            \n",
        "            \n",
        "#         return blockOutputs\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms import CenterCrop\n",
        "# class Decoder(nn.Module): #Using convTraspose2D\n",
        "#     def __init__(self, channels = (16,8,4,2)):\n",
        "#         super().__init__()\n",
        "#         #initialize number of channels, upsampler blocks, and decoder blocks\n",
        "#         self.channels = channels\n",
        "\n",
        "#         self.upconvs = nn.ModuleList(\n",
        "#             [nn.ConvTranspose2d(channels[i], channels[i+1], kernel_size=2, stride=2)\n",
        "#             for i in range(len(channels)-1)]\n",
        "#         )\n",
        "#         self.dec_blocks = nn.ModuleList(\n",
        "#             [Block(channels[i], channels[i+1])\n",
        "#             for i in range(len(channels)-1)]\n",
        "#             )\n",
        "        \n",
        "#     def forward(self,x, encFeatures):\n",
        "#         for i in range(len(self.channels)-1):\n",
        "#            # print(i)\n",
        "#             x = self.upconvs[i](x)\n",
        "\n",
        "#             #Crop the current features from encoder blocks and concate them with current upsampled features and pass the out to the center decoder block\n",
        "#             encfeat = self.crop(encFeatures[i],x) \n",
        "#             x = torch.cat([x,encfeat], dim=1) #Dim could be wrong\n",
        "#             x = self.dec_blocks[i](x)\n",
        "#         return x\n",
        "    \n",
        "#     def crop(self,encFeatures,x):\n",
        "#         (_,_,H,W) = x.shape\n",
        "#         encFeatures = CenterCrop([H,W])(encFeatures)\n",
        "\n",
        "#         return encFeatures\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "# class unet(nn.Module):\n",
        "#     def __init__(self, encChannels = (1,2,4,8,16,32),\n",
        "#         decChannels = (32,16,8,4,2), nbClasses =1, retainDim=True, \n",
        "#         outSize = (240,240)):\n",
        "#         super().__init__()\n",
        "#         self.encoder = Encoder(encChannels)\n",
        "#         self.decoder = Decoder(decChannels)\n",
        "\n",
        "#         self.head = nn.Conv2d(decChannels[-1], nbClasses, 1)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "#         self.retainDim  = retainDim\n",
        "#         self.outSize = outSize\n",
        "                \n",
        "#     def forward(self,x):\n",
        "#         encfeatures = self.encoder(x) #Grab features from encoder\n",
        "\n",
        "#         decfeatures = self.decoder(encfeatures[::-1][0], encfeatures[::-1][1:])\n",
        "\n",
        "#         map = self.head(decfeatures)\n",
        "\n",
        "#         if self.retainDim:\n",
        "#             map = F.interpolate(map,self.outSize)\n",
        "            \n",
        "#         map = self.sigmoid(map)\n",
        "#         return map \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfmThYKIFJsO",
        "outputId": "af351da3-9dda-4446-a960-4b956252db41"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch.nn as nn\n",
        "import truenet_model_utils\n",
        "\n",
        "#=========================================================================================\n",
        "# Triplanar U-Net ensemble network (TrUE-Net) model\n",
        "# Vaanathi Sundaresan\n",
        "# 09-03-2021, Oxford\n",
        "#=========================================================================================\n",
        "\n",
        "class TrUENet(nn.Module):\n",
        "    '''\n",
        "    TrUE-Net model definition\n",
        "    '''\n",
        "    def __init__(self, n_channels=1, n_classes=2, init_channels=64, plane='axial', bilinear=False):\n",
        "        super(TrUENet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.init_channels = init_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.n_layers = 3\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inpconv = truenet_model_utils.OutConv(n_channels, 3, name=\"inpconv_\")\n",
        "        if plane == 'axial':\n",
        "            self.convfirst = truenet_model_utils.DoubleConv(3, init_channels, 3, name=\"convfirst_\")\n",
        "        else:\n",
        "            self.convfirst = truenet_model_utils.DoubleConv(3, init_channels, 5, name=\"convfirst_\")\n",
        "        self.down1 = truenet_model_utils.Down(init_channels, init_channels*2, 3, name=\"down1_\")\n",
        "        self.down2 = truenet_model_utils.Down(init_channels*2, init_channels*4, 3, name=\"down2_\")\n",
        "        self.down3 = truenet_model_utils.Down(init_channels*4, init_channels*8, 3, name=\"down3_\")\n",
        "        self.up3 = truenet_model_utils.Up(init_channels*8, init_channels*4, 3, \"up1_\", bilinear)\n",
        "        self.up2 = truenet_model_utils.Up(init_channels*4, init_channels*2, 3, \"up2_\", bilinear)\n",
        "        self.up1 = truenet_model_utils.Up(init_channels*2, init_channels, 3, \"up3_\", bilinear)\n",
        "        self.outconv = truenet_model_utils.OutConv(init_channels, n_classes, name=\"outconv_\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        xi = self.inpconv(x)\n",
        "        x1 = self.convfirst(xi)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x = self.up3(x4, x3)\n",
        "        x = self.up2(x, x2)\n",
        "        x = self.up1(x, x1)\n",
        "        logits = self.outconv(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peu7HxUTFeNM",
        "outputId": "c5930e9e-652b-4ca9-bd90-30ab6ccc0ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: module OutConv is treated as a zero-op.\n",
            "Warning: module DoubleConv is treated as a zero-op.\n",
            "Warning: module Down is treated as a zero-op.\n",
            "Warning: module Up is treated as a zero-op.\n",
            "Warning: module TrUENet is treated as a zero-op.\n",
            "TrUENet(\n",
            "  8.563 M, 100.000% Params, 44.002 GMac, 100.000% MACs, \n",
            "  (inpconv): OutConv(\n",
            "    0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, \n",
            "    (conv): Sequential(\n",
            "      0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, \n",
            "      (inpconv_conv): Conv2d(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, 1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (convfirst): DoubleConv(\n",
            "    0.039 M, 0.455% Params, 2.252 GMac, 5.119% MACs, \n",
            "    (double_conv): Sequential(\n",
            "      0.039 M, 0.455% Params, 2.252 GMac, 5.119% MACs, \n",
            "      (convfirst_conv1): Conv2d(0.002 M, 0.021% Params, 0.103 GMac, 0.235% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (convfirst_bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.007 GMac, 0.017% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (convfirst_relu1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.008% MACs, inplace=True)\n",
            "      (convfirst_conv2): Conv2d(0.037 M, 0.431% Params, 2.127 GMac, 4.834% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (convfirst_bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.007 GMac, 0.017% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (convfirst_relu2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.008% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down1): Down(\n",
            "    0.222 M, 2.592% Params, 3.203 GMac, 7.280% MACs, \n",
            "    (maxpool_conv): Sequential(\n",
            "      0.222 M, 2.592% Params, 3.203 GMac, 7.280% MACs, \n",
            "      (down1_maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.004 GMac, 0.008% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (down1_conv1): Conv2d(0.074 M, 0.862% Params, 1.064 GMac, 2.417% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down1_bn1): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.008% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down1_relu1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.004% MACs, inplace=True)\n",
            "      (down1_conv2): Conv2d(0.148 M, 1.723% Params, 2.125 GMac, 4.830% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down1_bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.008% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down1_relu2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.004% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down2): Down(\n",
            "    0.886 M, 10.350% Params, 3.194 GMac, 7.259% MACs, \n",
            "    (maxpool_conv): Sequential(\n",
            "      0.886 M, 10.350% Params, 3.194 GMac, 7.259% MACs, \n",
            "      (down2_maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.002 GMac, 0.004% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (down2_conv1): Conv2d(0.295 M, 3.447% Params, 1.063 GMac, 2.415% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down2_bn1): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down2_relu1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
            "      (down2_conv2): Conv2d(0.59 M, 6.891% Params, 2.124 GMac, 4.828% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down2_bn2): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down2_relu2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down3): Down(\n",
            "    3.542 M, 41.364% Params, 3.19 GMac, 7.249% MACs, \n",
            "    (maxpool_conv): Sequential(\n",
            "      3.542 M, 41.364% Params, 3.19 GMac, 7.249% MACs, \n",
            "      (down3_maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (down3_conv1): Conv2d(1.18 M, 13.782% Params, 1.062 GMac, 2.414% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down3_bn1): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down3_relu1): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
            "      (down3_conv2): Conv2d(2.36 M, 27.558% Params, 2.124 GMac, 4.827% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down3_bn2): BatchNorm2d(0.001 M, 0.012% Params, 0.001 GMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down3_relu2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (up3): Up(\n",
            "    2.951 M, 34.461% Params, 10.768 GMac, 24.471% MACs, \n",
            "    (up): ConvTranspose2d(1.18 M, 13.779% Params, 4.39 GMac, 9.978% MACs, 512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      1.771 M, 20.682% Params, 6.377 GMac, 14.494% MACs, \n",
            "      (double_conv): Sequential(\n",
            "        1.771 M, 20.682% Params, 6.377 GMac, 14.494% MACs, \n",
            "        (up1_conv1): Conv2d(1.18 M, 13.779% Params, 4.248 GMac, 9.653% MACs, 512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up1_bn1): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up1_relu1): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
            "        (up1_conv2): Conv2d(0.59 M, 6.891% Params, 2.124 GMac, 4.828% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up1_bn2): BatchNorm2d(0.001 M, 0.006% Params, 0.002 GMac, 0.004% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up1_relu2): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.002% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up2): Up(\n",
            "    0.738 M, 8.620% Params, 10.705 GMac, 24.327% MACs, \n",
            "    (up): ConvTranspose2d(0.295 M, 3.445% Params, 4.32 GMac, 9.817% MACs, 256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      0.443 M, 5.175% Params, 6.385 GMac, 14.510% MACs, \n",
            "      (double_conv): Sequential(\n",
            "        0.443 M, 5.175% Params, 6.385 GMac, 14.510% MACs, \n",
            "        (up2_conv1): Conv2d(0.295 M, 3.445% Params, 4.249 GMac, 9.655% MACs, 256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up2_bn1): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.008% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up2_relu1): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.004% MACs, inplace=True)\n",
            "        (up2_conv2): Conv2d(0.148 M, 1.723% Params, 2.125 GMac, 4.830% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up2_bn2): BatchNorm2d(0.0 M, 0.003% Params, 0.004 GMac, 0.008% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up2_relu2): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.004% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up1): Up(\n",
            "    0.185 M, 2.158% Params, 10.686 GMac, 24.284% MACs, \n",
            "    (up): ConvTranspose2d(0.074 M, 0.862% Params, 4.286 GMac, 9.740% MACs, 128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (conv): DoubleConv(\n",
            "      0.111 M, 1.296% Params, 6.4 GMac, 14.544% MACs, \n",
            "      (double_conv): Sequential(\n",
            "        0.111 M, 1.296% Params, 6.4 GMac, 14.544% MACs, \n",
            "        (up3_conv1): Conv2d(0.074 M, 0.862% Params, 4.25 GMac, 9.660% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up3_bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.007 GMac, 0.017% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up3_relu1): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.008% MACs, inplace=True)\n",
            "        (up3_conv2): Conv2d(0.037 M, 0.431% Params, 2.127 GMac, 4.834% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (up3_bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.007 GMac, 0.017% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (up3_relu2): ReLU(0.0 M, 0.000% Params, 0.004 GMac, 0.008% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (outconv): OutConv(\n",
            "    0.0 M, 0.001% Params, 0.004 GMac, 0.009% MACs, \n",
            "    (conv): Sequential(\n",
            "      0.0 M, 0.001% Params, 0.004 GMac, 0.009% MACs, \n",
            "      (outconv_conv): Conv2d(0.0 M, 0.001% Params, 0.004 GMac, 0.009% MACs, 64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Computational complexity:       44.0 GMac\n",
            "Number of parameters:           8.56 M  \n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "  net = TrUENet()\n",
        "  macs, params = get_model_complexity_info(net, (1, 240 , 240), as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module): #-log(Dice)\n",
        "    def __init__(self,weights=None, size_average=True):\n",
        "        super(DiceLoss,self).__init__()\n",
        "\n",
        "    def forward(self,inputs,targets,smooth=1e-16): #Inputs is the prediction\n",
        "        # print(inputs.shape)\n",
        "        # print(targets.shape)\n",
        "        #Flatten label and prediciton tensors\n",
        "        #inputs = torch.round(inputs)        \n",
        "        # inputs[inputs>0.5] = 1.0\n",
        "        # inputs[inputs<=0.5]=0.0\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs*targets).sum()\n",
        "        union = inputs.sum() + targets.sum()\n",
        "        #dice_log = -torch.log(2*intersection + 2*smooth) + torch.log(inputs.sum() + targets.sum() + smooth)\n",
        "        dice_loss = -torch.log(2*intersection+ smooth) + torch.log(union + smooth)        \n",
        "\n",
        "        return dice_loss\n",
        "        #return dice_log\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "z9QqxCyzAn5_",
        "outputId": "996ed53c-39a5-4e63-e979-57f88807a9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*******************************************************\n",
            "Model will be saved to  : savedRightModels/32fms/lr0.0001_NOepochs_bs128_20Apr_1122pm_model\n",
            "----------------------------------------------------------\n",
            "Number of training samples 1860\n",
            "Number of validation samples 465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [608,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [128,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [129,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [130,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [131,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [132,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [261,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [192,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [193,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [194,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [195,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [196,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [971,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [972,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [973,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [974,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [975,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [976,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [977,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [978,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [979,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [980,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [365,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [366,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [367,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [368,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [369,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [370,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [371,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [908,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [909,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [910,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [911,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [912,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [913,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [914,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [915,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [916,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [917,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [668,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [669,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [670,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [50,0,0], thread: [671,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [43,0,0], thread: [675,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [43,0,0], thread: [676,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [43,0,0], thread: [677,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [43,0,0], thread: [678,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [43,0,0], thread: [679,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [868,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [869,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [870,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [871,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [872,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [873,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [388,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [389,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [390,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [8,0,0], thread: [391,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "[W python_anomaly_mode.cpp:104] Warning: Error detected in NllLoss2DBackward0. Traceback of forward call that caused the error:\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
            "    handle._run()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n",
            "    await result\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n",
            "0it [00:00, ?it/s]= await reply_co"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 240, 240])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ntent\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3301, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_382131/338961304.py\", line 115, in <cell line: 97>\n",
            "    loss   = criterion(output, trainLabels.squeeze())\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1150, in forward\n",
            "    return F.cross_entropy(input, target, weight=self.weight,\n",
            "  File \"/home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
            " (function _print_stack)\n",
            "\n",
            "/opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/cuda/NLLLoss2d.cu:95: nll_loss2d_forward_kernel: block: [49,0,0], thread: [866,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/cds/Desktop/MIG Course project/Self Segmentation project/Using TrUE Net/Brain_Tumor_Seg_TrUENet.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e32342e33382e3336222c2275736572223a22636473227d/home/cds/Desktop/MIG%20Course%20project/Self%20Segmentation%20project/Using%20TrUE%20Net/Brain_Tumor_Seg_TrUENet.ipynb#ch0000016vscode-remote?line=117'>118</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e32342e33382e3336222c2275736572223a22636473227d/home/cds/Desktop/MIG%20Course%20project/Self%20Segmentation%20project/Using%20TrUE%20Net/Brain_Tumor_Seg_TrUENet.ipynb#ch0000016vscode-remote?line=119'>120</a>\u001b[0m \u001b[39m# back propagate\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e32342e33382e3336222c2275736572223a22636473227d/home/cds/Desktop/MIG%20Course%20project/Self%20Segmentation%20project/Using%20TrUE%20Net/Brain_Tumor_Seg_TrUENet.ipynb#ch0000016vscode-remote?line=120'>121</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e32342e33382e3336222c2275736572223a22636473227d/home/cds/Desktop/MIG%20Course%20project/Self%20Segmentation%20project/Using%20TrUE%20Net/Brain_Tumor_Seg_TrUENet.ipynb#ch0000016vscode-remote?line=122'>123</a>\u001b[0m \u001b[39m# Accumulate loss for current minibatch\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e32342e33382e3336222c2275736572223a22636473227d/home/cds/Desktop/MIG%20Course%20project/Self%20Segmentation%20project/Using%20TrUE%20Net/Brain_Tumor_Seg_TrUENet.ipynb#ch0000016vscode-remote?line=123'>124</a>\u001b[0m runtrainloss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()        \n",
            "File \u001b[0;32m~/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m~/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/cds/anaconda3/envs/MIG_Course/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "import os,time\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.io\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "#Data augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.RandomVerticalFlip(0.4),\n",
        "    transforms.RandomHorizontalFlip(0.4),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "print ('*******************************************************')\n",
        "\n",
        "start_time=time.time()\n",
        "saveDir='savedRightModels/32fms/lr0.0001_NOepochs_bs128_'\n",
        "cwd=os.getcwd()\n",
        "directory=saveDir+datetime.now().strftime(\"%d%b_%I%M%P_\")+'model'\n",
        "print('Model will be saved to  :', directory)\n",
        "#wandb.init()\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "a = 'Image_Training/A_images.csv' # define the path of csv file of images\n",
        "b = 'Labels_Training/A_labels.csv' # define the path of csv files of labels\n",
        "c = '' # define the path of root directory of images\n",
        "\n",
        "\n",
        "# make the data iterator for training data\n",
        "train_data = BrainTumor(a, b, c,  transforms.ToTensor())\n",
        "batchSize = 64\n",
        "learning_rate = 5e-4\n",
        "validation_split = 0.2\n",
        "\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split*dataset_size))\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = valid_sampler)\n",
        "\n",
        "print('----------------------------------------------------------')\n",
        "print(\"Number of training samples \"+str(dataset_size-split))\n",
        "print(\"Number of validation samples \"+str(split))\n",
        "#%%class BrainTumor(Dataset)\n",
        "# Create the object for the network\n",
        "\n",
        "  \n",
        "net = TrUENet()\n",
        "#wandb.watch(net)\n",
        "#CUDA_LAUNCH_BLOCKING=0\n",
        "net.cuda()\n",
        "\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(net.parameters(),lr=learning_rate)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=33, gamma=0.1)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()#DiceLoss() #Add custom loss and change later\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Iterate over the training dataset\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "sens = []\n",
        "spec = []\n",
        "acc  = []\n",
        "img_rows = 512\n",
        "img_cols = 512\n",
        "numImgs  = 5 # should be same as mini batch size\n",
        "epochs = 50\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "min_valid_loss = np.inf\n",
        "for j in range(epochs):  \n",
        "    # Start epochs   \n",
        "    runtrainloss = 0\n",
        "    net.train() \n",
        "    for i,data in tqdm.tqdm(enumerate(trainloader)): \n",
        "        # start iterations\n",
        "        images,trainLabels = Variable(data[0]),Variable(data[1])\n",
        "        \n",
        "        \n",
        "        images  = images.cuda()\n",
        "        trainLabels = trainLabels.cuda()\n",
        "        #print(trainLabels.shape)  \n",
        "        #print(np.unique(trainLabels))      \n",
        "        # make forward pass      \n",
        "        output = net(images)\n",
        "       \n",
        "        #compute loss\n",
        "        print(output.shape)\n",
        "        loss   = criterion(output, trainLabels.squeeze())        \n",
        "                \n",
        "        # make gradients zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # back propagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Accumulate loss for current minibatch\n",
        "        runtrainloss += loss.item()        \n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()       \n",
        "\n",
        "        #wandb.log({\"-log(Dice)\":loss, \"Dice\":torch.exp(-loss)})\n",
        "        \n",
        "       \n",
        "    # print loss after every epoch\n",
        "    net.eval()\n",
        "    validloss=0.0\n",
        "    \n",
        "    for data,labels in validloader:\n",
        "        if torch.cuda.is_available:\n",
        "            data,labels = data.cuda(), labels.cuda()\n",
        "        target = net(data)\n",
        "        loss = criterion(target, labels.squeeze())\n",
        "        validloss += loss.item()\n",
        "\n",
        "\n",
        "    print('Training - Epoch {}/{}, loss:{:.4f} '.format(j+1, epochs, runtrainloss/len(trainloader)))\n",
        "    train_loss.append(runtrainloss/len(trainloader))\n",
        "    valid_loss.append(validloss/len(validloader))\n",
        "    print('Validation loss {:.4f}'.format(validloss/len(validloader)))\n",
        "    \n",
        "       \n",
        "    # Take a step for scheduler\n",
        "    #scheduler.step()\n",
        "    \n",
        "    \n",
        "    #save the model  \n",
        "    avg_valid_loss = validloss/len(validloader)\n",
        "\n",
        "    if avg_valid_loss < min_valid_loss and avg_valid_loss>0:\n",
        "        print(\"Current valid loss {:.4f} less than minimum valid loss {:.4f}\".format(avg_valid_loss, min_valid_loss))\n",
        "        min_valid_loss = avg_valid_loss        \n",
        "        print(\"Saving model\")\n",
        "        torch.save(net.state_dict(), os.path.join(directory,\"Unet_Epochs\"+str(j+1)+\"_validLoss{:.4f}_model.pth\".format(min_valid_loss)))\n",
        "    #torch.save(net.state_dict(),os.path.join(directory,\"Unet_\" + str(j+1) +\"_model.pth\"))\n",
        "    if avg_valid_loss<0:\n",
        "        epochs = j\n",
        "        print(\"Model has overfitted a lot\")\n",
        "        print(\"Stopping training\")\n",
        "        break\n",
        "    if avg_valid_loss < 0.01:\n",
        "        epochs = j+1\n",
        "        print(\"Done training.\")\n",
        "        break\n",
        "    \t    \n",
        "\n",
        "# Save the train stats\n",
        "\n",
        "np.save(directory+'/trnloss.npy',np.array(train_loss) )\n",
        "\n",
        "\n",
        "# plot the training loss\n",
        "\n",
        "# x = range(epochs)\n",
        "# plt.figure()\n",
        "\n",
        "# plt.xlabel('epochs')\n",
        "# plt.ylabel('Train Loss ') \n",
        "# plt.legend(loc=\"upper left\")  \n",
        "# plt.show()\n",
        "             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq5t6qt-VIdM"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plot the loss\n",
        "x = range(epochs)\n",
        "plt.figure()\n",
        "plt.plot(x,train_loss,label='Training')\n",
        "plt.plot(x,valid_loss,label='validation')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Loss ') \n",
        "plt.legend(loc=\"upper right\")  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Single testing\n",
        "# path = \"savedRightModels/lr0.0001_200epochs_bs256/BEst_Model_30Dec_0733pm_model/Unet_Epochs99_validLoss0.0424_model.pth\"\n",
        "# checkpoint = torch.load(path)\n",
        "# net = unet()\n",
        "# net.load_state_dict(checkpoint)\n",
        "# net.cuda()\n",
        "# net.eval()\n",
        "# target = 0\n",
        "# for data,labels in validloader:   \n",
        "#     if torch.cuda.is_available:\n",
        "#         data,labels = data.cuda(), labels.cuda()\n",
        "#     target = net(data)        \n",
        "#     #target_round = torch.round(target)    \n",
        "#     #target_round = target_round.cpu().detach().numpy()  \n",
        "#     target = target.cpu().detach().numpy()    \n",
        "#     print(target.shape)\n",
        "#     plt.imshow(target[1,0,:,:])\n",
        "\n",
        "    \n",
        "#     #loss = criterion(target, labels.squeeze())\n",
        "    \n",
        "#     #print(1-loss)\n",
        "#     plt.imshow(data.cpu().detach().numpy()[1,0,:,:], cmap=\"bone\", origin=\"lower\")\n",
        "#     plt.title(\"MRI\")    \n",
        "#     plt.show()\n",
        "\n",
        "#     plt.imshow(labels.cpu().detach().numpy()[1,:,:], cmap=\"bone\", origin=\"lower\")\n",
        "#     plt.title(\"Ground Truth\")\n",
        "#     plt.show()\n",
        "#     #plt.imshow(target[0,0,:,:], cmap=\"bone\",origin=\"lower\")\n",
        "#     break\n",
        "# #target[target>0.5]=1.0\n",
        "# target = target[1,0,:,:]\n",
        "# print(target.shape)\n",
        "# plt.imshow(target, cmap=\"bone\", origin=\"lower\")\n",
        "# plt.title(\"predicton\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Brain_Tumor_Seg",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
