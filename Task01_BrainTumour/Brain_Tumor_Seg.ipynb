{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qviQjOd1Yu1U",
        "outputId": "24f6efcb-81c1-4260-a654-1e7fa869a83c"
      },
      "outputs": [],
      "source": [
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "basepath_images= \"imagesTr/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE3WoYQHY9np"
      },
      "outputs": [],
      "source": [
        "#import nibabel as nib\n",
        "import csv\n",
        "import imageio\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', '.*do not.*', )\n",
        "import nibabel as nib \n",
        "\n",
        "def preprocess_img(img):\n",
        "  return (img-img.mean())/(img.std()+1e-16)\n",
        "\n",
        "fields = ['Name']\n",
        "\n",
        "\n",
        "new_img_dir = \"/home/cds/Desktop/MIG Course project/Self Segmentation project/Task01_BrainTumour/Image_Training/\"\n",
        "filename = new_img_dir+\"A_images.csv\"\n",
        "# writing to csv file \n",
        "# with open(filename, 'w') as csvfile:\n",
        "#   writer = csv.writer(csvfile) \n",
        "#   writer.writerow(fields) \n",
        "#   for i in range(0, 15):\n",
        "#     img = nib.load(basepath_images+'BRATS_' + '{0:03}'.format(i+1) + '.nii.gz')\n",
        "#     img_arr  = img.get_fdata()\n",
        "#     #print(img_arr.shape) #(240,240,155,4) i.e channel size at end\n",
        "    \n",
        "#     for j in range(0, img_arr.shape[2]):\n",
        "#       im = img_arr[:,:,j,0]\n",
        "#       im = preprocess_img(im)      \n",
        "#       #print(im)\n",
        "#       img_uint8 = im.astype(np.uint8)      \n",
        "#       file_name = new_img_dir+'image_' + str(i+1) + '_' + str(j+1) + '_.png'\n",
        "#       imageio.imwrite(file_name, im)       \n",
        "#       writer.writerow([file_name]) \n",
        "    \n",
        "    \n",
        "      \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "AUDIco0isK3b",
        "outputId": "3ad38b44-a614-400f-c239-8f01e095ddd2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.imshow(plt.imread('Image_Training/image_1_62_.png'))\n",
        "#print(np.unique(plt.imread('Images_Tr/image_1_62_.png')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLSkfkCqtwT-",
        "outputId": "10f2ee5c-dbae-4d62-f374-307852a5d4b5"
      },
      "outputs": [],
      "source": [
        "labels_path = \"labelsTr/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPCgdUCpsJfO"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import csv\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_label(label):\n",
        "  label[label>0] = 1.0\n",
        "  return label\n",
        "\n",
        "\n",
        "fields = ['Name']\n",
        "\n",
        "new_labels_dir = \"/home/cds/Desktop/MIG Course project/Self Segmentation project/Task01_BrainTumour/Labels_Training/\"\n",
        "filename = new_labels_dir+\"A_labels.csv\"\n",
        "    \n",
        "# writing to csv file \n",
        "# with open(filename, 'w') as csvfile:\n",
        "#   writer = csv.writer(csvfile) \n",
        "#   writer.writerow(fields) \n",
        "#   for i in range(0, 15):\n",
        "#     img = nib.load(labels_path+'BRATS_' + '{0:03}'.format(i+1) + '.nii.gz')\n",
        "#     img_arr  = img.get_fdata()\n",
        "#     #print(img_arr.shape)\n",
        "#     for j in range(0, img_arr.shape[2]):\n",
        "#       im = img_arr[:,:,j]\n",
        "#       im = preprocess_label(im)\n",
        "#       #print(im.shape)\n",
        "#       img_uint8 = im.astype(np.uint8)\n",
        "#       file_name = new_labels_dir+'label_' + str(i+1) + '_' + str(j+1) + '_.png'\n",
        "#       imageio.imwrite(file_name, im)\n",
        "#       writer.writerow([file_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "test_label = 'Labels_Training/label_2_92_.png'\n",
        "test_img_label = plt.imread(test_label)\n",
        "print(np.unique(test_img_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOeKAPtlr_ED"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3PgOYTfAbn0"
      },
      "outputs": [],
      "source": [
        "class BrainTumor(Dataset):\n",
        "    \"\"\"Brain Tumor Segmentation Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file_images, csv_file_labels, root_dir, transform):# transform to tensor\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.names_images = pd.read_csv(csv_file_images)\n",
        "        self.names_labels = pd.read_csv(csv_file_labels)\n",
        "        self.root_dirIimgs = root_dir + 'Image_Training/'\n",
        "        self.root_dirIlabl = root_dir + 'Labels_Training/'\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "\n",
        "        img_name = os.path.join(self.root_dirIimgs,\n",
        "                                self.names_images['Name'][idx])\n",
        "        lab_name = os.path.join(self.root_dirIlabl,\n",
        "                                self.names_labels['Name'][idx])\n",
        "        image = io.imread(img_name)\n",
        "        label = io.imread(lab_name)\n",
        "\n",
        "        #Data augmentation\n",
        "        \n",
        "        if self.transform:  \n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label).long()\n",
        "        # label[label<255]=0\n",
        "        # label = label/255\n",
        "        # label = label.long()\n",
        "        return image,label  # transform the images into tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,inChannels, outChannels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inChannels,outChannels,kernel_size=3)        \n",
        "        self.conv2 = nn.Conv2d(outChannels,outChannels,kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        # Apply conv1=>conv2 => relu        \n",
        "        tmp = self.conv1(x)\n",
        "        tmp = self.relu(tmp)\n",
        "        tmp = self.conv2(tmp)\n",
        "        tmp = self.relu(tmp)        \n",
        "        return tmp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,channels = (1,2,4,8,16)):\n",
        "        super().__init__()\n",
        "\n",
        "        #Store encoder and maxpooling\n",
        "        self.encBlocks = nn.ModuleList(\n",
        "            [Block(channels[i],channels[i+1])\n",
        "             for i in range(len(channels)-1)])\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        blockOutputs = []\n",
        "\n",
        "        for i,block in enumerate(self.encBlocks):\n",
        "            #Pass inputs through the current encoder block, store the outputs and then apply maxpooling            \n",
        "            x = block(x)\n",
        "            blockOutputs.append(x)\n",
        "            x = self.pool(x)\n",
        "            \n",
        "            \n",
        "        return blockOutputs\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms import CenterCrop\n",
        "class Decoder(nn.Module): #Using convTraspose2D\n",
        "    def __init__(self, channels = (16,8,4,2)):\n",
        "        super().__init__()\n",
        "        #initialize number of channels, upsampler blocks, and decoder blocks\n",
        "        self.channels = channels\n",
        "\n",
        "        self.upconvs = nn.ModuleList(\n",
        "            [nn.ConvTranspose2d(channels[i], channels[i+1], kernel_size=2, stride=2)\n",
        "            for i in range(len(channels)-1)]\n",
        "        )\n",
        "        self.dec_blocks = nn.ModuleList(\n",
        "            [Block(channels[i], channels[i+1])\n",
        "            for i in range(len(channels)-1)]\n",
        "            )\n",
        "        \n",
        "    def forward(self,x, encFeatures):\n",
        "        for i in range(len(self.channels)-1):\n",
        "           # print(i)\n",
        "            x = self.upconvs[i](x)\n",
        "\n",
        "            #Crop the current features from encoder blocks and concate them with current upsampled features and pass the out to the center decoder block\n",
        "            encfeat = self.crop(encFeatures[i],x) \n",
        "            x = torch.cat([x,encfeat], dim=1) #Dim could be wrong\n",
        "            x = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self,encFeatures,x):\n",
        "        (_,_,H,W) = x.shape\n",
        "        encFeatures = CenterCrop([H,W])(encFeatures)\n",
        "\n",
        "        return encFeatures\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "class unet(nn.Module):\n",
        "    def __init__(self, encChannels = (1,2,4,8,16,32),\n",
        "        decChannels = (32,16,8,4,2), nbClasses =1, retainDim=True, \n",
        "        outSize = (240,240)):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(encChannels)\n",
        "        self.decoder = Decoder(decChannels)\n",
        "\n",
        "        self.head = nn.Conv2d(decChannels[-1], nbClasses, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.retainDim  = retainDim\n",
        "        self.outSize = outSize\n",
        "                \n",
        "    def forward(self,x):\n",
        "        encfeatures = self.encoder(x) #Grab features from encoder\n",
        "\n",
        "        decfeatures = self.decoder(encfeatures[::-1][0], encfeatures[::-1][1:])\n",
        "\n",
        "        map = self.head(decfeatures)\n",
        "\n",
        "        if self.retainDim:\n",
        "            map = F.interpolate(map,self.outSize)\n",
        "            \n",
        "        map = self.sigmoid(map)\n",
        "        return map \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfmThYKIFJsO",
        "outputId": "af351da3-9dda-4446-a960-4b956252db41"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peu7HxUTFeNM",
        "outputId": "c5930e9e-652b-4ca9-bd90-30ab6ccc0ca9"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "  net = unet()\n",
        "  macs, params = get_model_complexity_info(net, (1, 240 , 240), as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module): #-log(Dice)\n",
        "    def __init__(self,weights=None, size_average=True):\n",
        "        super(DiceLoss,self).__init__()\n",
        "\n",
        "    def forward(self,inputs,targets,smooth=1e-16): #Inputs is the prediction\n",
        "        # print(inputs.shape)\n",
        "        # print(targets.shape)\n",
        "        #Flatten label and prediciton tensors\n",
        "        #inputs = torch.round(inputs)        \n",
        "        # inputs[inputs>0.5] = 1.0\n",
        "        # inputs[inputs<=0.5]=0.0\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs*targets).sum()\n",
        "        union = inputs.sum() + targets.sum()\n",
        "        #dice_log = -torch.log(2*intersection + 2*smooth) + torch.log(inputs.sum() + targets.sum() + smooth)\n",
        "        dice_loss = -torch.log(2*intersection+ smooth) + torch.log(union + smooth)        \n",
        "        #dice_loss = (2.*intersection)/(union+smooth)\n",
        "\n",
        "        return dice_loss\n",
        "        #return dice_log\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os,time\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.io\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "#Data augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.RandomVerticalFlip(0.4),\n",
        "    transforms.RandomHorizontalFlip(0.4),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "print ('*******************************************************')\n",
        "\n",
        "start_time=time.time()\n",
        "saveDir='savedRightModels/32fms/lr0.0001_NOepochs_bs128_'\n",
        "cwd=os.getcwd()\n",
        "directory=saveDir+datetime.now().strftime(\"%d%b_%I%M%P_\")+'model'\n",
        "print('Model will be saved to  :', directory)\n",
        "#wandb.init()\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "a = 'Image_Training/A_images.csv' # define the path of csv file of images\n",
        "b = 'Labels_Training/A_labels.csv' # define the path of csv files of labels\n",
        "c = '' # define the path of root directory of images\n",
        "\n",
        "\n",
        "# make the data iterator for training data\n",
        "train_data = BrainTumor(a, b, c,  transforms.ToTensor())\n",
        "batchSize = 158\n",
        "learning_rate = 5e-4\n",
        "validation_split = 0.2\n",
        "\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split*dataset_size))\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = valid_sampler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "z9QqxCyzAn5_",
        "outputId": "996ed53c-39a5-4e63-e979-57f88807a9ad"
      },
      "outputs": [],
      "source": [
        "import os,time\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.io\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "#Data augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.RandomVerticalFlip(0.4),\n",
        "    transforms.RandomHorizontalFlip(0.4),\n",
        "    transforms.Resize((240,240)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "print ('*******************************************************')\n",
        "\n",
        "start_time=time.time()\n",
        "saveDir='savedRightModels/32fms/lr0.0001_NOepochs_bs128_'\n",
        "cwd=os.getcwd()\n",
        "directory=saveDir+datetime.now().strftime(\"%d%b_%I%M%P_\")+'model'\n",
        "print('Model will be saved to  :', directory)\n",
        "#wandb.init()\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "a = 'Image_Training/A_images.csv' # define the path of csv file of images\n",
        "b = 'Labels_Training/A_labels.csv' # define the path of csv files of labels\n",
        "c = '' # define the path of root directory of images\n",
        "\n",
        "\n",
        "# make the data iterator for training data\n",
        "train_data = BrainTumor(a, b, c,  transforms.ToTensor())\n",
        "batchSize = 158\n",
        "learning_rate = 5e-4\n",
        "validation_split = 0.2\n",
        "\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split*dataset_size))\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize,  num_workers=2, sampler = valid_sampler)\n",
        "\n",
        "print('----------------------------------------------------------')\n",
        "print(\"Number of training samples \"+str(dataset_size-split))\n",
        "print(\"Number of validation samples \"+str(split))\n",
        "#%%class BrainTumor(Dataset)\n",
        "# Create the object for the network\n",
        "\n",
        "  \n",
        "net = unet()\n",
        "#wandb.watch(net)\n",
        "#CUDA_LAUNCH_BLOCKING=0\n",
        "net.cuda()\n",
        "\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(net.parameters(),lr=learning_rate)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=33, gamma=0.1)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = DiceLoss() #Add custom loss and change later\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Iterate over the training dataset\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "sens = []\n",
        "spec = []\n",
        "acc  = []\n",
        "img_rows = 512\n",
        "img_cols = 512\n",
        "numImgs  = 5 # should be same as mini batch size\n",
        "epochs = 500\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "min_valid_loss = np.inf\n",
        "for j in range(epochs):  \n",
        "    # Start epochs   \n",
        "    runtrainloss = 0\n",
        "    net.train() \n",
        "    for i,data in tqdm.tqdm(enumerate(trainloader)): \n",
        "        # start iterations\n",
        "        images,trainLabels = Variable(data[0]),Variable(data[1])\n",
        "        \n",
        "        \n",
        "        images  = images.cuda()\n",
        "        trainLabels = trainLabels.cuda()\n",
        "        #print(trainLabels.shape)  \n",
        "        #print(np.unique(trainLabels))      \n",
        "        # make forward pass      \n",
        "        output = net(images)\n",
        "       \n",
        "        #compute loss\n",
        "        #print(output.shape)\n",
        "        loss   = criterion(output[:,0,:,:], trainLabels.squeeze())        \n",
        "                \n",
        "        # make gradients zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # back propagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Accumulate loss for current minibatch\n",
        "        runtrainloss += loss.item()        \n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()       \n",
        "\n",
        "        #wandb.log({\"-log(Dice)\":loss, \"Dice\":torch.exp(-loss)})\n",
        "        \n",
        "       \n",
        "    # print loss after every epoch\n",
        "    net.eval()\n",
        "    validloss=0.0\n",
        "    \n",
        "    for data,labels in validloader:\n",
        "        if torch.cuda.is_available:\n",
        "            data,labels = data.cuda(), labels.cuda()\n",
        "        target = net(data)\n",
        "        loss = criterion(target, labels.squeeze())\n",
        "        validloss += loss.item()\n",
        "\n",
        "\n",
        "    print('Training - Epoch {}/{}, loss:{:.4f} '.format(j+1, epochs, runtrainloss/len(trainloader)))\n",
        "    train_loss.append(runtrainloss/len(trainloader))\n",
        "    valid_loss.append(validloss/len(validloader))\n",
        "    print('Validation loss {:.4f}'.format(validloss/len(validloader)))\n",
        "    \n",
        "       \n",
        "    # Take a step for scheduler\n",
        "    #scheduler.step()\n",
        "    \n",
        "    \n",
        "    #save the model  \n",
        "    avg_valid_loss = validloss/len(validloader)\n",
        "\n",
        "    if avg_valid_loss < min_valid_loss and avg_valid_loss>0:\n",
        "        print(\"Current valid loss {:.4f} less than minimum valid loss {:.4f}\".format(avg_valid_loss, min_valid_loss))\n",
        "        min_valid_loss = avg_valid_loss        \n",
        "        print(\"Saving model\")\n",
        "        torch.save(net.state_dict(), os.path.join(directory,\"Unet_Epochs\"+str(j+1)+\"_validLoss{:.4f}_model.pth\".format(min_valid_loss)))\n",
        "    #torch.save(net.state_dict(),os.path.join(directory,\"Unet_\" + str(j+1) +\"_model.pth\"))\n",
        "    if avg_valid_loss<0:\n",
        "        epochs = j\n",
        "        print(\"Model has overfitted a lot\")\n",
        "        print(\"Stopping training\")\n",
        "        break\n",
        "    if avg_valid_loss < 0.01:\n",
        "        epochs = j+1\n",
        "        print(\"Done training.\")\n",
        "        break\n",
        "    \t    \n",
        "\n",
        "# Save the train stats\n",
        "\n",
        "np.save(directory+'/trnloss.npy',np.array(train_loss) )\n",
        "\n",
        "\n",
        "# plot the training loss\n",
        "\n",
        "# x = range(epochs)\n",
        "# plt.figure()\n",
        "\n",
        "# plt.xlabel('epochs')\n",
        "# plt.ylabel('Train Loss ') \n",
        "# plt.legend(loc=\"upper left\")  \n",
        "# plt.show()\n",
        "             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq5t6qt-VIdM"
      },
      "outputs": [],
      "source": [
        "#Plot the loss\n",
        "#Time taken for training 4 minutes\n",
        "print(epochs)\n",
        "x = range(epochs)\n",
        "plt.figure()\n",
        "plt.plot(x,train_loss,label='Training')\n",
        "plt.plot(x,valid_loss,label='validation')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Loss ') \n",
        "plt.legend(loc=\"upper right\")  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Single testing\n",
        "path = \"/home/cds/Desktop/MIG Course project/Self Segmentation project/Task01_BrainTumour/savedRightModels/32fms/lr0.0001_NOepochs_bs128_22Apr_0354pm_model/Unet_Epochs177_validLoss0.0059_model.pth\"\n",
        "checkpoint = torch.load(path)\n",
        "net = unet()\n",
        "net.load_state_dict(checkpoint)\n",
        "net.cuda()\n",
        "net.eval()\n",
        "target = 0\n",
        "for data,labels in validloader:   \n",
        "    if torch.cuda.is_available:\n",
        "        data,labels = data.cuda(), labels.cuda()\n",
        "    target = net(data)        \n",
        "    #target_round = torch.round(target)    \n",
        "    #target_round = target_round.cpu().detach().numpy()  \n",
        "    target = target.cpu().detach().numpy()    \n",
        "    print(target.shape)\n",
        "    plt.imshow(target[1,0,:,:])\n",
        "\n",
        "    \n",
        "    #loss = criterion(target, labels.squeeze())\n",
        "    \n",
        "    #print(1-loss)\n",
        "    plt.imshow(data.cpu().detach().numpy()[1,0,:,:], cmap=\"bone\", origin=\"lower\")\n",
        "    plt.title(\"MRI\")    \n",
        "    plt.show()\n",
        "\n",
        "    plt.imshow(labels.cpu().detach().numpy()[1,:,:], cmap=\"bone\", origin=\"lower\")\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.show()\n",
        "    #plt.imshow(target[0,0,:,:], cmap=\"bone\",origin=\"lower\")\n",
        "    break\n",
        "#target[target>0.5]=1.0\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(target.shape)\n",
        "tar = target[157,0,:,:]\n",
        "print(tar.shape)\n",
        "plt.imshow(tar, cmap=\"bone\", origin=\"lower\")\n",
        "plt.title(\"predicton\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Brain_Tumor_Seg",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
